
{
    
    
    
    
        
        
        
    
        
        
        
    
        
        
        
    
        
        
        
    
        
        
        
    
        
        
        
    
        
        
        
    
    "pages": [{"date":"2023-04-11","image":"","imageAlt":"","link":"https://idev-blog.web.app/posts/awesome-resource-collector/","summary":"Data Race Patterns in Go A data race is a concurrency bug that occurs when two or more goroutines access the same datum, at least one of them is write, and there is no ordering between them. Data races are insidious bug and must be avoided at all costs.","tags":[],"text":"data race patterns in go a data race is a concurrency bug that occurs when two or more goroutines access the same datum, at least one of them is write, and there is no ordering between them. data races are insidious bug and must be avoided at all costs.\nhttps://www.uber.com/en-vn/blog/data-race-patterns-in-go/\n","title":"Awesome resources collector"},{"date":"2023-03-03","image":"","imageAlt":"","link":"https://idev-blog.web.app/posts/golang-channel-usecase/","summary":"Lập trình bất đồng bộ (asynchronous) và đồng thời (concurrency) trở lên dễ dàng với channel trong Golang. Synchronization với channel có phạm vi sử dụng lớn và nhiều biến thể hơn so với các mô hình khác như actoc model hay async/await pattern.","tags":["channel","concurrency","golang"],"text":"lập trình bất đồng bộ (asynchronous) và đồng thời (concurrency) trở lên dễ dàng với channel trong golang. synchronization với channel có phạm vi sử dụng lớn và nhiều biến thể hơn so với các mô hình khác như actoc model hay async/await pattern.\ntrong bài này mình sẽ tổng hợp lại các trường hợp sử dụng channel trong golang, mục đích chính là sử dụng nhiều nhất có thể (chứ không phải là trường hợp tốt nhất) có thể các kĩ thuật khác về synchronization sẽ tốt hơn.\nsử dụng channel như futures/promises future và promises được sử dụng trong nhiều ngôn ngữ khác nhau. chúng thường được sử dụng dưới dạng requests và responses.\nlười làm thì thuê - return receive-only channel\ntrong ví dụ dưới longtimerequest xử lý async bằng cách trả về receive-only channel. mỗi hàm longtimerequest thực hiện hết 1s (sleep). bằng cách đưa phần sleep (minh họa cho workload nào đó) chạy dưới goroutine và trả về ngay receive-only channel thì giúp x2 thời gian thực hiện.\nfunc main() { now := time.now() // do async r1, r2 := longtimerequest(), longtimerequest() getresponse(r1) getresponse(r2) log.println(\u0026#34;since: \u0026#34;, time.since(now)) } func longtimerequest() \u0026lt;-chan string { ch := make(chan string) now := time.now() // async here go func() { time.sleep(time.second) ch \u0026lt;- fmt.sprintf(\u0026#34;long time request response after: %v\u0026#34;, time.since(now)) close(ch) }() return ch } func getresponse(ch \u0026lt;-chan string) { log.println(\u0026lt;-ch) } lười làm thì thuê - pass send-only channels\nthay vì trả về receive-only channel, ta có thể sử dụng send-only channels như là một phương pháp thay thế. tuy nhiên mình thấy cách receive-only channel sử dụng clean hơn.\nfunc main() { now := time.now() // sử dụng buffered channel để tránh block khi gửi ch := make(chan string, 2) go longtimerequest(ch) go longtimerequest(ch) getresponse(ch) getresponse(ch) log.println(\u0026#34;since: \u0026#34;, time.since(now)) } func longtimerequest(ch chan\u0026lt;- string) { now := time.now() time.sleep(time.second) ch \u0026lt;- fmt.sprintf(\u0026#34;long time request response after: %v\u0026#34;, time.since(now)) } func getresponse(ch \u0026lt;-chan string) { log.println(\u0026lt;-ch) } ai nhanh thì thắng - the first response win\nmột ngày đẹp trời, cà rốt của bạn đăng story: tối nay tớ rảnh? bạn suy nghĩ hết nửa tiếng đồng hồ rồi reply để hẹn địa điểm, thì nhận được câu trả lời là tớ set kèo đi với người khác rồi. thực ra là dù có reply sớm thì cà rốt cũng chả đi với bạn đâu :v tuy nhiên bạn đến muộn thì người ta có cái cớ rất chi là hợp lí để từ chối. không lan man nữa, vào việc thôi.\nfunc main() { now := time.now() queue := 10 ok := make(chan int, queue) for i := 0; i \u0026lt; queue; i++ { go reply(ok, i) } // ai nhanh thì thắng firstrepsonse := \u0026lt;-ok log.println(\u0026#34;since: \u0026#34;, time.since(now), \u0026#34;pos\u0026#34;, firstrepsonse) } func init() { rand.seed(time.now().unix()) } func reply(ch chan\u0026lt;- int, pos int) { rd := rand.intn(3) + 1 time.sleep(time.duration(rd) * time.second) ch \u0026lt;- pos } chú ý là phải dùng buffered channel để tránh ăn send block của channel nhé (goroutine leak problem). đoạn code trên còn vấn đề là chẳng hạn cà rốt chỉ đăng tin cho người nào đó xem thôi, người đó reply rồi thì cà rốt thêm một tin mới là đã tìm được người cần tìm rồi. thế là bạn cũng không cần reply lại nữa. vậy xử lý thế nào nhỉ?\ncâu trả lời là dùng context\nfunc main() { now := time.now() queue := 10 ok := make(chan int, queue) ctx, cancel := context.withcancel(context.background()) for i := 0; i \u0026lt; queue; i++ { go reply(ctx, ok, i) } // ai nhanh thì thắng firstrepsonse := \u0026lt;-ok cancel() log.println(\u0026#34;since: \u0026#34;, time.since(now), \u0026#34;pos\u0026#34;, firstrepsonse) } func init() { rand.seed(time.now().unix()) } func reply(ctx context.context, ch chan\u0026lt;- int, pos int) { rd := rand.intn(3) + 1 select { case \u0026lt;-time.after(time.duration(rd) * time.second): log.println(\u0026#34;run\u0026#34;) case \u0026lt;-ctx.done(): log.println(\u0026#34;cancel\u0026#34;) } ch \u0026lt;- pos } sử dụng channel để notification đừng kể với ai nhé - 1-to-1 notification\nmột ngày đẹp trời, bạn được đi chơi riêng với cà rốt, có những điều từ lâu bạn đã muốn nói riêng với cô ấy. hôm nay bạn mới có cơ hội vậy thì thắt dây an toàn và vào việc thôi.\nfunc main() { ch := make(chan string) go secret(ch) log.println(\u0026lt;-ch) } func secret(ch chan\u0026lt;- string) { time.sleep(time.second) ch \u0026lt;- \u0026#34;this is secret\u0026#34; } gửi đám bạn thân - 1-to-n notification\nbên trên bạn chỉ thổ lộ riêng với cà rốt, bạn nghĩ điều đó là bí mật riêng của hai người, nhưng mà biết đâu được, bạn đâu kiểm soát được nó. bí mật chỉ là bí mật khi chỉ có một người biết thôi. ví dụ cô ấy gửi tấm chân tình của bạn đến đám bạn thân chẳng hạn :v.\ncó nhiều cách để thực hiện 1-to-n notification. cách đơn giản nhất là close channel. do tính chất: sau khi close channel thì receive value từ channel luôn luôn không bị block (receive zero value).\nfunc main() { ch := make(chan string) n := 10 for i := 0; i \u0026lt; n; i++ { go notify(ch) } close(ch) time.sleep(time.second) } func notify(ch \u0026lt;-chan string) { \u0026lt;-ch fmt.println(\u0026#34;receive notify\u0026#34;) } phản hồi về bí mật - n-to-1 notification\nbí mật của bạn bị chia sẻ ra thì có lẽ nó cũng sẽ nhận được nhiều lời bàn tán. cách dễ nhất để nhận nhiều lời bàn tán là dùng sync.waitgroup.\nfunc main() { n := 10 wg := \u0026amp;sync.waitgroup{} wg.add(n) for i := 0; i \u0026lt; n; i++ { go notify(wg) } wg.wait() } func notify(wg *sync.waitgroup) { defer wg.done() fmt.println(\u0026#34;send notify\u0026#34;) } sử dụng channels như mutex locks\nchannel với capacity bằng 1 có thể sử dụng như buffered channel. tuy nhiên thì dùng cho vui thôi chứ thực tế chả ai dùng channel chỉ để implement lại cái mutex làm gì cả :3\ntype empty struct{} func main() { ch := make(chan empty, 1) cnt := 0 wg := sync.waitgroup{} n := 100 wg.add(n) for i := 0; i \u0026lt; n; i++ { go func() { defer wg.done() for i := 0; i \u0026lt; 1000; i++ { ch \u0026lt;- empty{} cnt++ \u0026lt;-ch } }() } wg.wait() log.println(\u0026#34;cnt: \u0026#34;, cnt) } đoạn code trên dùng channel để đảm bảo synchronize cho biến cnt. channel phải là buffered channel với cap = 1 để đảm bảo lần lock đầu tiên không bị block. nếu không sẽ bị deadlock do ông nào cũng đòi khóa mà không ai chịu trả khóa.\nsử dụng channels như counting semaphores buffered channel có thể sử dụng để implement semaphores. counting semaphore có thể xem là multi-owner locks. nếu cap của một channel là n thì nó có thể xem là một cái khóa cho phép n người sử dụng tại một thời điểm. counting semaphores thường được sử dụng để giới hạn số lượng tài nguyên như số lượng concurrent request tối đa \u0026hellip;\nví dụ khi bạn vào quán cafe, quán chỉ phục vụ một số lượng chỗ ngồi nhất định, hết chỗ thì \u0026hellip; mời bạn về. dĩ nhiên rồi, chả nhẽ bạn lại đứng để uống cafe, mà có khi chỗ còn không có mà đứng ấy chứ. thế làm sao để thông báo cho khách biết là đã hết chỗ rồi (ví dụ như khách đặt bàn online). cách đơn giản là bạn phải duy trì một biến để đếm số lượng khách trong quán.\ntype seat int type bar chan seat func (bar bar) servecustomer(c int) { log.print(\u0026#34;customer#\u0026#34;, c, \u0026#34; enters the bar\u0026#34;) seat := \u0026lt;-bar // receive value from bar log.print(\u0026#34;++ customer#\u0026#34;, c, \u0026#34;drinks at seat#\u0026#34;, seat) time.sleep(time.second * time.duration(10+rand.intn(6))) log.print(\u0026#34;-- customer#\u0026#34;, c, \u0026#34; free seat#\u0026#34;, seat) bar \u0026lt;- seat // release } func main() { rand.seed(time.now().unixnano()) bar24x7 := make(bar, 10) for seatid := 0; seatid \u0026lt; cap(bar24x7); seatid++ { bar24x7 \u0026lt;- seat(seatid) } for customerid := 0; ; customerid++ { log.println(\u0026#34;num goroutine: \u0026#34;, runtime.numgoroutine()) go bar24x7.servecustomer(customerid) } } đoạn code trên đảm bảo chỉ có nhiều nhất 10 người được phục vụ tại một thời điểm. mặc dù chỉ có nhiều nhất 10 người được phục vụ tại một thời điểm, tuy nhiên có nhiều hơn 10 customers ở trong hàng đợi để chờ phục vụ (\u0026gt; 10 goroutines), càng lâu thì số lượng goroutine này càng lớn. từ đó sẽ bị tồn đọng và không bao giờ xử lý hết. do tốc độ tạo mới nhiều hơn tốc độ consume.\nvậy làm sao để giới hạn số lượng goroutine có thể tạo ra? ý tưởng là dùng một buffered channel với cap là số lượng channel lớn nhất có thể tồn tại tại một thời điểm.\ntype seat int type bar chan seat func (bar bar) servecustomer(c int, seat seat) { log.print(\u0026#34;++ customer#\u0026#34;, c, \u0026#34;drinks at seat#\u0026#34;, seat) time.sleep(time.second * time.duration(2+rand.intn(6))) log.print(\u0026#34;-- customer#\u0026#34;, c, \u0026#34; free seat#\u0026#34;, seat) bar \u0026lt;- seat // free seat and leave the bar } func main() { rand.seed(time.now().unixnano()) bar24x7 := make(bar, 10) for seatid := 0; seatid \u0026lt; cap(bar24x7); seatid++ { bar24x7 \u0026lt;- seat(seatid) } for customerid := 0; ; customerid++ { log.println(\u0026#34;num goroutine: \u0026#34;, runtime.numgoroutine()) // need a seed to serve next customer seat := \u0026lt;-bar24x7 go bar24x7.servecustomer(customerid, seat) } } đoạn chương trình trên chỉ đảm bảo được có 10 goroutines tồn tại đồng thời. tuy nhiên cần tạo rất nhiều goroutines trong quá trình hoạt động (mỗi khi free seat thì lại cần tạo một goroutine mới để xử lý).\nđể tối ưu hơn, cần viết một chương trình đảm bảo chỉ có tối đa 10 goroutines tồn tại đồng thời và tối đa 10 goroutines được tạo ra. đoạn code dưới đây thực hiện yêu cầu này.\nfunc main() { rand.seed(time.now().unixnano()) maxserve := 10 consumers := make(chan int) for i := 0; i \u0026lt; maxserve; i++ { go servecustomer(consumers) } for i := 0; ; i++ { log.println(\u0026#34;num goroutines:\u0026#34;, runtime.numgoroutine()) consumers \u0026lt;- i } } func servecustomer(consumers chan int) { for consumer := range consumers { log.println(\u0026#34;++ customer#\u0026#34;, consumer, \u0026#34;drinks at the bar\u0026#34;) time.sleep(time.second * time.duration(2+rand.intn(6))) log.println(\u0026#34;-- customer#\u0026#34;, consumer, \u0026#34;leaves the bar\u0026#34;) } } channel encapsulated in channel try-send và try-receive đến channel khi sử dụng select block với nhánh default và chỉ một nhánh case được gọi là try-send hoặc try-receive (tùy vào nhánh case triển khai ra sao). try-send và try-receive không bao giờ block.\nfunc main() { type book struct{ id int } bookshelf := make(chan book, 3) for i := 0; i \u0026lt; cap(bookshelf)*2; i++ { select { case bookshelf \u0026lt;- book{id: i}: fmt.println(\u0026#34;succeeded to put book\u0026#34;) default: fmt.println(\u0026#34;failed to put book\u0026#34;) } } for i := 0; i \u0026lt; cap(bookshelf)*2; i++ { select { case book := \u0026lt;-bookshelf: fmt.println(\u0026#34;succeeded to get book\u0026#34;, book.id) default: fmt.println(\u0026#34;failed to get book\u0026#34;) } } } check if a channel is closed without blocking the current goroutine\nnếu có thể chắc chắn rằng không có values nào gửi đến channel nữa thì ta có thể sử dụng đoạn code sau (concurrently and safely) để kiểm tra xem một channel đã close hay chưa mà không cần block goroutine hiện tại.\nfunc isclose(c chan int) bool { select { case _, ok := \u0026lt;-c: return ok default: } return false } peak/burst limiting\ncác cách khác để implement first-response win ta có thể sử dụng select mechanism (try-send) với buffered channel có capacity bằng 1 (ít nhất 1) để implement first-response-win.\nfunc main() { rand.seed(time.now().unixnano()) c := make(chan int, 1) for i := 0; i \u0026lt; 5; i++ { go source(c) } rnd := \u0026lt;-c // only the first response win fmt.println(rnd) select {} } func source(c chan\u0026lt;- int) { now := time.now() defer func() { log.println(\u0026#34;end call to source after:\u0026#34;, time.since(now)) }() fmt.println(\u0026#34;call to source\u0026#34;) ra, rb := rand.int(), rand.intn(3)+1 // sleep 1s, 2s, 3s time.sleep(time.duration(rb) * time.second) // try send select { case c \u0026lt;- ra: default: } } phiên bản trên kết quả thì đúng nhưng sử dụng tài nguyên là thừa thãi. do khi đã có first-response rồi thì không cần phải tiếp tục thực thi việc gọi đến source nữa.\nfunc main() { ctx, cancel := context.withcancel(context.background()) c := make(chan int, 1) for i := 0; i \u0026lt; 5; i++ { go source(ctx, c) } rnd := \u0026lt;-c // only the first response win cancel() log.println(\u0026#34;winner: \u0026#34;, rnd) time.sleep(time.second * 5) fmt.println(\u0026#34;number of goroutines:\u0026#34;, runtime.numgoroutine()) } func source(ctx context.context, c chan\u0026lt;- int) { now := time.now() fn := func(ctx context.context) \u0026lt;-chan int { rand.seed(time.now().unixnano()) fmt.println(\u0026#34;call to source\u0026#34;) // try-send ch := make(chan int, 1) ra, rb := rand.int(), rand.intn(3)+1 select { // simulate work load, we don\u0026#39;t need to call when context is canceled case \u0026lt;-time.after(time.duration(rb) * time.second): defer func() { log.println(\u0026#34;end call to source after:\u0026#34;, time.since(now)) }() ch \u0026lt;- ra case \u0026lt;-ctx.done(): } return ch } select { case \u0026lt;-ctx.done(): log.println(ctx.err()) case v := \u0026lt;-fn(ctx): select { case c \u0026lt;- v: default: } } } rate limiting we can also use try-send to do rate limiting . in practice, rate-limit is often to avoid quota exceeding and resource exhaustion.\nfan-in bạn cân viết một chương trình đi crawl data từ một source sau đó in ra console.\nfunc main() { rand.seed(time.now().unixnano()) c := crawl() // forward to another source for i := 0; i \u0026lt; 5; i++ { log.println(\u0026lt;-c) } } func crawl() chan string { c := make(chan string) go func() { for i := 0; ; i++ { c \u0026lt;- fmt.sprintf(\u0026#34;crawl %d\u0026#34;, i) time.sleep(time.duration(rand.intn(1e3)) * time.millisecond) } }() return c } yêu cầu mới là bạn phải crawl từ 2 source khác nhau, sau đó in ra console.\nfunc main() { rand.seed(time.now().unixnano()) c1 := crawl(\u0026#34;crawl1\u0026#34;, time.second) c2 := crawl(\u0026#34;crawl2\u0026#34;, time.second*5) // forward to another source for i := 0; i \u0026lt; 10; i++ { log.println(\u0026lt;-c1) log.println(\u0026lt;-c2) } } func crawl(id string, sleeptime time.duration) chan string { c := make(chan string) go func() { for i := 0; ; i++ { c \u0026lt;- fmt.sprintf(\u0026#34;crawl for %s: %d\u0026#34;, id, i) time.sleep(sleeptime) } }() return c } kết quả trả ra là một kết quả tuần tự crawl1,crawl2,crawl1,crawl2\u0026hellip; crawl1 phải đợi crawl2 đi crawl xong thì mới được chạy.\n2023/04/04 16:35:06 crawl for crawl1: 0 2023/04/04 16:35:06 crawl for crawl2: 0 2023/04/04 16:35:07 crawl for crawl1: 1 2023/04/04 16:35:11 crawl for crawl2: 1 2023/04/04 16:35:11 crawl for crawl1: 2 2023/04/04 16:35:16 crawl for crawl2: 2 2023/04/04 16:35:16 crawl for crawl1: 3 2023/04/04 16:35:21 crawl for crawl2: 3 2023/04/04 16:35:21 crawl for crawl1: 4 sếp yêu cầu kết quả bạn crawl phải là realtime. fan-in chính là giải pháp\nfunc main() { rand.seed(time.now().unixnano()) c1 := crawl(\u0026#34;crawl1\u0026#34;, time.second) c2 := crawl(\u0026#34;crawl2\u0026#34;, time.second*5) c := fanin(c1, c2) // forward to another source for i := 0; i \u0026lt; 10; i++ { log.println(\u0026lt;-c) } } func crawl(id string, sleeptime time.duration) chan string { c := make(chan string) go func() { for i := 0; ; i++ { c \u0026lt;- fmt.sprintf(\u0026#34;crawl for %s: %d\u0026#34;, id, i) time.sleep(sleeptime) } }() return c } func fanin(c ...chan string) \u0026lt;-chan string { fi := make(chan string) for _, v := range c { go func(v chan string) { for i := range v { fi \u0026lt;- i } }(v) } return fi } kết quả đa số kết quả sẽ từ crawl1 vì crawl1 chạy nhanh hơn.\n2023/04/04 16:35:57 crawl for crawl1: 0 2023/04/04 16:35:57 crawl for crawl2: 0 2023/04/04 16:35:58 crawl for crawl1: 1 2023/04/04 16:35:59 crawl for crawl1: 2 2023/04/04 16:36:00 crawl for crawl1: 3 2023/04/04 16:36:01 crawl for crawl1: 4 2023/04/04 16:36:02 crawl for crawl2: 1 2023/04/04 16:36:02 crawl for crawl1: 5 2023/04/04 16:36:03 crawl for crawl1: 6 2023/04/04 16:36:04 crawl for crawl1: 7 để sử dụng fan-in, luồng dữ liệu phải không phụ thuộc lẫn nhau\nđoạn code bên trên chưa graceful close channel và có goroutine leak. chú ý phần này.\nfunc main() { rand.seed(time.now().unixnano()) ctx, cancel := context.withcancel(context.background()) c1 := crawl(ctx, \u0026#34;crawl1\u0026#34;, time.millisecond*1) c2 := crawl(ctx, \u0026#34;crawl2\u0026#34;, time.millisecond*2) c := fanin(ctx, c1, c2) // forward to another source for i := 0; i \u0026lt; 2; i++ { log.println(\u0026lt;-c) } cancel() // _ = cancel time.sleep(time.second * 1) log.println(\u0026#34;num goroutines:\u0026#34;, runtime.numgoroutine()) } func crawl(ctx context.context, id string, sleeptime time.duration) chan string { c := make(chan string) go func() { defer func() { log.println(\u0026#34;exit crawl goroutine\u0026#34;) }() for { select { case c \u0026lt;- fmt.sprintf(\u0026#34;crawl for %s\u0026#34;, id): case \u0026lt;-ctx.done(): log.printf(\u0026#34;close %s\\n\u0026#34;, id) close(c) return } } }() return c } func fanin(ctx context.context, c ...chan string) \u0026lt;-chan string { fi := make(chan string) wg := sync.waitgroup{} for _, v := range c { wg.add(1) go func(v chan string) { defer func() { wg.done() log.println(\u0026#34;exit fanin goroutine\u0026#34;) }() for i := range v { select { case fi \u0026lt;- i: case \u0026lt;-ctx.done(): return } } }(v) } go func() { defer func() { log.println(\u0026#34;exit wg goroutine\u0026#34;) }() wg.wait() close(fi) }() return fi } the tee-channel switches thao tác gửi hay nhận trên một nil channel đều bị block. với tính chất này ta có thể kiểm soát được cơ chế selection trong select block.\ncontrol code execution possibility weights ta có thể duplicate nhánh case trong select code block để tăng khả năng thực hiện đoạn code tương ứng.\nfunc main() { foo, bar := make(chan struct{}), make(chan struct{}) close(foo) close(bar) x, y := 0.0, 0.0 f := func() { x++ } g := func() { y++ } for i := 0; i \u0026lt; 10000; i++ { select { case \u0026lt;-foo: f() case \u0026lt;-foo: f() case \u0026lt;-bar: g() } } fmt.println(x / y) // about 2 } data flow manipulations ","title":"Một vài cách sử dụng channel trong golang"},{"date":"2022-11-08","image":"","imageAlt":"","link":"https://idev-blog.web.app/posts/linux-auto-connect-openvpn/","summary":"The OpenVPN is an open source Virtual Private Network (VPN) project. It creates secure connections over the Internet using a custom security protocol that utilizes SSL/TLS.\nIn this article, i will introduce naive solution for automatic connect to VPN using openvpn and systemd management.","tags":["linux"],"text":"the openvpn is an open source virtual private network (vpn) project. it creates secure connections over the internet using a custom security protocol that utilizes ssl/tls.\nin this article, i will introduce naive solution for automatic connect to vpn using openvpn and systemd management.\ncreate vpn script\n# create script connect to vpn mkdir -p ~/scripts cd ~/scripts touch vpn.sh sudo chmod +x vpn.sh install oauthtool\nsudo apt install oathtool ~/scripts/vpn.sh\nvpn_user=\u0026#34;\u0026#34; # insert vpn user here vpn_password=\u0026#34;\u0026#34; # insert vpn password here otp_key=\u0026#34;\u0026#34; # insert otp key here ovpn_file=\u0026#34;\u0026#34; # insert path to .ovpn file here. example /home/admicro-bigdata.ovpn vpn_auth=\u0026#34;$(oathtool -b --totp $otp_key)$vpn_password\u0026#34; echo $vpn_password | sudo -s bash -c \u0026#34;openvpn --config $ovpn_file --auth-user-pass \u0026lt;(echo -e \u0026#39;$vpn_user\\n$vpn_auth\u0026#39;) --daemon\u0026#34; create systemd service\ncd /lib/systemd/system sudo touch vpn.service /lib/systemd/system/vpn.service\n[unit] description=auto connect vccorp\u0026#39;s vpn service. [service] type=forking user=root # path to vpn file, example: /home/ngoctd/scripts/vpn.sh execstart=/bin/bash /home/ngoctd/scripts/vpn.sh # path to vpn file, example: /home/ngoctd/scripts/vpn.sh execreload= /bin/bash /home/ngoctd/scripts/vpn.sh execstop=sudo killall openvpn restart=on-failure restartsec=10s [install] wantedby=multi-user.target start,stop,auto restart service\nsudo systemctl daemon-reload # reload systemd daemon sudo systemctl enable vpn # auto start when vpn was killed sudo systemctl start vpn # start vpn sudo systemctl status vpn # check vpn status sudo systemctl stop vpn # stop vpn ","title":"Automatic connect to VPN"},{"date":"2022-11-05","image":"","imageAlt":"","link":"https://idev-blog.web.app/posts/programming-language-channel-in-golang/","summary":"Channel is an important built-in feature in Go. It is one of the features makes Go unique. Channel makes concurrent programming convenient, fun and lowers the difficulties of concurrent programming. Channel mainly acts as a concurrency synchronization technique. To understand channels better, the internal structure of channels and some implementation details by the standard Go compiler/runtime are also simply described.","tags":["basic","golang"],"text":"channel is an important built-in feature in go. it is one of the features makes go unique. channel makes concurrent programming convenient, fun and lowers the difficulties of concurrent programming. channel mainly acts as a concurrency synchronization technique. to understand channels better, the internal structure of channels and some implementation details by the standard go compiler/runtime are also simply described.\nchannel introduction don\u0026rsquo;t communicate by sharing memory, share memory by communicating.\ncommunicating by sharing memory and sharing by communicating are two programming manners in concurrent programming. when goroutines communicate by sharing memory, we use traditional concurrency sychronization techniques, such as mutex locks, to protect the shared memory to prevent data racts.\ngo also provides another concurrency sychronization technique, channel. channels make goroutines share memory by communicating. we can view a channel as an internal fifo queu within a program. some goroutines send values to the queue (the channel) and some other goroutines receive values from the queue.\nalong with transfering values (through channels), the ownership of some values may also be transferred between goroutines (ownership on logic view). when a goroutine send a value to a channel, we can view the goroutine releases the ownership of some values. when a goroutine receives a value from a channel, we can view the goroutine acquires the ownerships of some values.\nchannel value comparisons all channel types are comparable types. if one channel value is assigned to another, the two channels share the same underlying part(s). in other words, those two channels represent the same internal channel object. the result of comparing them is true.\ndetailed explanations for channel operations operation a nil channel a closed channel a not-closed non-nil channel close panic panic success send value to block for ever panic block or succeed to send receive value from block for ever never block block or success to receive to bettern understand channel types and values, and to make some explainations easier, looking in the raw internal structures of internal channel objects is very helpful.\nwe can think of each channel consistin of three queues internally:\nthe receiving goroutine queue (generally fifo). the queue is a linked list without size limitation. goroutines in this queue are all in blocking state and waiting to receive values from that channel.\nthe sending goroutine queue (generally fifo). the queue is also a linked list without size limitation. goroutines in this queue are all in blocking state and waiting to send values to that channel.\nthe value buffer queue (absolutely fifo). this is a circular queue. its size is equal to the capacity of the channel. if the current number of values stored in the value buffer queue of the channel reaches the capacity of the channel, the channel is called in full status. if no values are store in the value buffer queue of the channel currently, the channel is called in empty status. for a zero-capacity (unbuffered) channel is also in both full and empty status.\neach channel internally holds a mutex lock which is used to avoid data races in all kinds of operations\nchannel operation: try to receive when a goroutine r tries to receive a value from a not-closed non-nil channel, the goroutine r will acquire the lock associated with the channel firstly, the do the following steps until one condition is satisfied.\ncheck buffer, if the value buffer queue of the channel is not empty. the receiving goroutine queue of the channel must be empty ( buffer != empty =\u0026gt; receiveing queue == emtpy ). the goroutine r will receive (by unshifting) a value from the value buffer queue. if the sending goroutine queue of the channel is also not empty, a sending goroutine will be unshifted out of the sending goroutine queue and resumed to running state again. the value the just unshifted sending goroutine trying to send will be pushed into the value buffer queue of the channel. the receiving goroutine r continues running. for this scenario, the channel receive operation is called a non-blocking operation. the goroutine r will receive a value from the value buffer queue. the goroutine r will recceive a value from the value buffer queue. sending goroutine is not empty. goroutine s send value to buffer and enter running state again. -\u0026gt; the receiving goroutine r continues running. the channel receive operation is called a non-blocking operation\ncheck buffer, the value buffer of the channel is empty. if the sending goroutine queue of the channel is not empty, in which case the channel must be an unbuffered channel, the receiving goroutine r will unshift value from a send goroutine. the just unshifted sending goroutine will get unblocked and resumed to running state again. -\u0026gt; the receiving goroutine r continues running. the channel receive operation is called a non-blocking operation\nif value buffer queue and the sending goroutine queue of the channel are both emtpy, the goroutine r will be pushed into the receiving goroutine queue of the channel and enter (and stay in) blocking state. it may be resumed to running state when another goroutine sends a value to the channel later. -\u0026gt; the receiving goroutine r enter blocking state. the channel receive operation is called a blocking operation\nchannel operation: try to send when a goroutine s tries to send a value to a not-closed non-nil channel, the goroutine s will acquire the lock associated with the channel firstly, then do the following steps until one step condition is satisfied.\ncheck receiving goroutine queue. if the receiving goroutine queue of the channel is not empty, in which case the value buffer queue of the channel must be empty, the sending goroutine s will unshift a receiving goroutine from the receiving goroutine queue of the channel and send the value to the just unshifted receiving goroutine. the just unshifted receiving goroutine will get unblocked and resumed to running state again. -\u0026gt; the sending goroutine s continues running. the channel send operation is called a non-blocking operation\ncheck receiving goroutine queue (empty), check buffer queue ( not full ), in which case the sending goroutine queue must be also empty, the value the sending goroutine s trying to send will be pushed into the value buffer queue. -\u0026gt; the sending goroutine s continues running. the channel send operation is called a non-blocking operation\ncheck receiving goroutine queue (empty), check buffer queue ( full ), the sending goroutine s will be pushed into the sending goroutine queue of the channel and enter (and stay in) blocking state. it may be resumed to running state when another goroutine receives a value from the channel later. -\u0026gt; the sending goroutine s enter blocking. the channel send operation is called a blocking operation\nonce a non-nil channel is closed, sending a value to the channel will produce a runtime panic in the current goroutine. note sending data to a closed channel is viewed as a non-blocking operation.\nchannel operation: try to close when a goroutine tries to close a not-closed non-nil channel, once the goroutine has acquired the lock of the channel, both of the following two steps will be performed by the following order.\nif the receiving goroutine queue of the channel is not empty, in which case the value buffer of the channel must be empty, all the goroutines in the receiving goroutine queue of the channel will be unshifted one by one, each of themm will receive a zero value of the elemenet type of the channel and be resumed to running state. if the sending goroutine queue of the channel is not empty, all the goroutines in the sending goroutine queue of the channel will be unshifted one by one and each of them will produce a panic for sending on a closed channel. this is the reason why we should avoid concurrent send and close operations on the same channel. after a channel is closed, the values which have been already pushed into the value buffer of the channel are still there.\nafter a non-nil channel is closed, channel receive operations os the channel will never block\nsome facts about the internal queues of a channel if the channel is closed, both its sending and receiving goroutine queue must be empty, but its value buffer may not be empty. at any time, if the value buffer is not empty, then its receiving goroutine queue must be empty. at any time, if the value buffer is not full, then its sending goroutine queue must be empty. if the channel is buffered, then at time, at least one of the channel\u0026rsquo;s goroutine queues must be empty (sending, receiving or both). if the channel is unbuffered, most of the time one of its sending goroutine queue and the receiving goroutine queue must be empty, with one exception. the exception is that a goroutine may be pushed into both of the two queues when execution a select control flow code block. references channel use case go101\n","title":"Channel in Golang"},{"date":"2022-10-13","image":"","imageAlt":"","link":"https://idev-blog.web.app/posts/poem-hai-%C4%91%E1%BB%A9a-tr%E1%BA%BB/","summary":"Hai đứa trẻ lớn lên nơi rừng núi\nXung quanh nhà nào là cỏ, là cây\nHai đứa trẻ là chị là em, và là bạn\nBạn bè xung quanh, hiếm lắm ấy mà.\nHai đứa trẻ nhiều đêm khó ngủ","tags":["thơ"],"text":"hai đứa trẻ lớn lên nơi rừng núi\nxung quanh nhà nào là cỏ, là cây\nhai đứa trẻ là chị là em, và là bạn\nbạn bè xung quanh, hiếm lắm ấy mà.\nhai đứa trẻ nhiều đêm khó ngủ\nbố mẹ đi rẫy mãi chưa về\nhai đứa trẻ ngồi bên ngọn nến sáng\nchỉ bóng trên tường, gọi mẹ xưng con.\nhai đứa trẻ rời xa nơi nương náu\nbố mẹ lo chuyện học hành mai sau\nhai đứa trẻ là chị là em, không là bạn\nnhảy dây, bị mắt, thú vị hơn nhiều.\nhai đứa trẻ mai này rồi cũng lớn\nđứa rời xóm làng, đứa tìm thủ đô\nhai đứa trẻ hiếm nào khi hỏi chuyện\nchuyện học hành, chuyện tương lai, chuyện mai sau\nhai đứa trẻ, hai đứa trẻ ấy không còn\u0026hellip;\n","title":"Hai Đứa Trẻ"},{"date":"2022-03-11","image":"","imageAlt":"","link":"https://idev-blog.web.app/posts/poem-m%C6%B0a/","summary":"Mưa,\nMưa trên mái hiên nhà\nĐến tận cánh đồng xa\nMưa,\nMưa hoài, mưa xối xả\nKìa ai đang thả thuyền lá\nKí ức trôi\nTrôi mãi tận miền xa.","tags":["thơ"],"text":"mưa,\nmưa trên mái hiên nhà\nđến tận cánh đồng xa\nmưa,\nmưa hoài, mưa xối xả\nkìa ai đang thả thuyền lá\nkí ức trôi\ntrôi mãi tận miền xa.\n","title":"Mưa"},{"date":"2021-11-20","image":"","imageAlt":"","link":"https://idev-blog.web.app/posts/poem-l%E1%BB%ADa-h%E1%BB%93ng/","summary":"Có một đốm than nhỏ\nThắp lên ngọn lửa hồng\nDành trọn nhiệt huyết nồng\nTháp sáng ước mơ to.","tags":["thơ"],"text":"có một đốm than nhỏ\nthắp lên ngọn lửa hồng\ndành trọn nhiệt huyết nồng\ntháp sáng ước mơ to.\n","title":"Lửa Hồng"}]
}

